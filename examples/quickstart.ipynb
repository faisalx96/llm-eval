{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM-Eval Quick Start\n",
    "\n",
    "This notebook walks you through evaluating your first LLM application with LLM-Eval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "# !pip install llm-eval\n",
    "\n",
    "from llm_eval import Evaluator\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Environment Check\n",
    "\n",
    "Your Langfuse credentials are already configured in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse configuration:\n",
      "Public key: âœ“\n",
      "Secret key: âœ“\n",
      "Host: https://cloud.langfuse.com\n"
     ]
    }
   ],
   "source": [
    "# Verify environment variables are set\n",
    "import os\n",
    "print(\"Langfuse configuration:\")\n",
    "print(f\"Public key: {'âœ“' if os.getenv('LANGFUSE_PUBLIC_KEY') else 'âœ—'}\")\n",
    "print(f\"Secret key: {'âœ“' if os.getenv('LANGFUSE_SECRET_KEY') else 'âœ—'}\")\n",
    "print(f\"Host: {os.getenv('LANGFUSE_HOST', 'Not set')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Your AI Function\n",
    "\n",
    "Let's create a simple Q&A bot to evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def simple_qa_bot(question: str) -> str:\n",
    "    \"\"\"A simple Q&A bot for demonstration.\"\"\"\n",
    "    question = question.lower()\n",
    "    \n",
    "    if \"capital of france\" in question:\n",
    "        return \"Paris\"\n",
    "    elif \"2+2\" in question or \"2 + 2\" in question:\n",
    "        return \"4\"\n",
    "    elif \"python\" in question:\n",
    "        return \"Python is a high-level programming language known for its simplicity and readability.\"\n",
    "    elif \"hello\" in question or \"hi\" in question:\n",
    "        return \"Hello! How can I help you today?\"\n",
    "    else:\n",
    "        return \"I'm not sure about that. Could you ask something else?\"\n",
    "\n",
    "# Test it\n",
    "print(simple_qa_bot(\"What is the capital of France?\"))\n",
    "print(simple_qa_bot(\"What is 2+2?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Dataset in Langfuse\n",
    "\n",
    "**Before running the evaluation, you need to:**\n",
    "\n",
    "1. Go to your Langfuse dashboard\n",
    "2. Navigate to Datasets â†’ New Dataset\n",
    "3. Create a dataset named \"quickstart-demo\"\n",
    "4. Add some test items:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"input\": \"What is the capital of France?\",\n",
    "  \"expected_output\": \"Paris\"\n",
    "}\n",
    "```\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"input\": \"What is 2+2?\", \n",
    "  \"expected_output\": \"4\"\n",
    "}\n",
    "```\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"input\": \"Tell me about Python\",\n",
    "  \"expected_output\": \"Python is a programming language\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run Your First Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">âœ… Evaluation complete!</span><span style=\"font-weight: bold\"> Processed </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\"> items with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> metrics</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mâœ… Evaluation complete!\u001b[0m\u001b[1m Processed \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m items with \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m metrics\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to migrate evaluation result: Instance <EvaluationRun at 0x130a08950a0> is not bound to a Session; attribute refresh operation cannot proceed (Background on this error at: https://sqlalche.me/e/20/bhk3)\n",
      "Failed to store evaluation run: Instance <EvaluationRun at 0x130a08950a0> is not bound to a Session; attribute refresh operation cannot proceed (Background on this error at: https://sqlalche.me/e/20/bhk3)\n",
      "Failed to store evaluation run in database: Instance <EvaluationRun at 0x130a08950a0> is not bound to a Session; attribute refresh operation cannot proceed (Background on this error at: https://sqlalche.me/e/20/bhk3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Overview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ <span style=\"font-weight: bold\">Dataset:</span> quickstart-demo         â”‚\n",
       "â”‚ <span style=\"font-weight: bold\">Total Items:</span> 3                   â”‚\n",
       "â”‚ <span style=\"font-weight: bold\">Success Rate:</span> 100.0%             â”‚\n",
       "â”‚ <span style=\"font-weight: bold\">Total Duration:</span> 0.7s             â”‚\n",
       "â”‚ <span style=\"font-weight: bold\">Average Item Time:</span> 0.48s Â± 0.23s â”‚\n",
       "â”‚ <span style=\"font-weight: bold\">Time Range:</span> [0.24s, 0.70s]       â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Overview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ \u001b[1mDataset:\u001b[0m quickstart-demo         â”‚\n",
       "â”‚ \u001b[1mTotal Items:\u001b[0m 3                   â”‚\n",
       "â”‚ \u001b[1mSuccess Rate:\u001b[0m 100.0%             â”‚\n",
       "â”‚ \u001b[1mTotal Duration:\u001b[0m 0.7s             â”‚\n",
       "â”‚ \u001b[1mAverage Item Time:\u001b[0m 0.48s Â± 0.23s â”‚\n",
       "â”‚ \u001b[1mTime Range:\u001b[0m [0.24s, 0.70s]       â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">               Evaluation Results: test_run                </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Metric      </span>â”ƒ<span style=\"font-weight: bold\">  Mean </span>â”ƒ<span style=\"font-weight: bold\"> Std Dev </span>â”ƒ<span style=\"font-weight: bold\">   Min </span>â”ƒ<span style=\"font-weight: bold\">   Max </span>â”ƒ<span style=\"font-weight: bold\"> Success </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> exact_match </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 0.667 </span>â”‚   0.577 â”‚ 0.000 â”‚ 1.000 â”‚<span style=\"color: #808000; text-decoration-color: #808000\">  100.0% </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m               Evaluation Results: test_run                \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mMetric     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m Mean\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mStd Dev\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m  Min\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m  Max\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mSuccess\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mexact_match\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m0.667\u001b[0m\u001b[32m \u001b[0mâ”‚   0.577 â”‚ 0.000 â”‚ 1.000 â”‚\u001b[33m \u001b[0m\u001b[33m 100.0%\u001b[0m\u001b[33m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator = Evaluator(\n",
    "    task=simple_qa_bot,\n",
    "    dataset=\"quickstart-demo\",\n",
    "    metrics=[\"exact_match\"],\n",
    "    config={\n",
    "        \"run_name\":\"test_run\",\n",
    "        \"run_metadata\": {\"model\": \"GPT4.1\"},\n",
    "        \"store_runs\": True,\n",
    "        \"project_id\": \"llm_eval\",\n",
    "        \"created_by\": \"faisal\",\n",
    "        \"tags\": [\"GPT4.1\", \"evaluation\", \"test\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "results = evaluator.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: View Your Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â•­â”€â”€â”€â”€â”€â”€â”€â”€ Overview â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ <span style=\"font-weight: bold\">Dataset:</span> quickstart-demo â”‚\n",
       "â”‚ <span style=\"font-weight: bold\">Total Items:</span> 3           â”‚\n",
       "â”‚ <span style=\"font-weight: bold\">Success Rate:</span> 100.0%     â”‚\n",
       "â”‚ <span style=\"font-weight: bold\">Duration:</span> 0.7s           â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â•­â”€â”€â”€â”€â”€â”€â”€â”€ Overview â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ \u001b[1mDataset:\u001b[0m quickstart-demo â”‚\n",
       "â”‚ \u001b[1mTotal Items:\u001b[0m 3           â”‚\n",
       "â”‚ \u001b[1mSuccess Rate:\u001b[0m 100.0%     â”‚\n",
       "â”‚ \u001b[1mDuration:\u001b[0m 0.7s           â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">         Evaluation Results: eval-20250725-195342          </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Metric      </span>â”ƒ<span style=\"font-weight: bold\">  Mean </span>â”ƒ<span style=\"font-weight: bold\"> Std Dev </span>â”ƒ<span style=\"font-weight: bold\">   Min </span>â”ƒ<span style=\"font-weight: bold\">   Max </span>â”ƒ<span style=\"font-weight: bold\"> Success </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> exact_match </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 0.667 </span>â”‚   0.577 â”‚ 0.000 â”‚ 1.000 â”‚<span style=\"color: #808000; text-decoration-color: #808000\">  100.0% </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> contains    </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 0.667 </span>â”‚   0.577 â”‚ 0.000 â”‚ 1.000 â”‚<span style=\"color: #808000; text-decoration-color: #808000\">  100.0% </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> fuzzy_match </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 0.000 </span>â”‚   0.000 â”‚ 0.000 â”‚ 0.000 â”‚<span style=\"color: #808000; text-decoration-color: #808000\">    0.0% </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m         Evaluation Results: eval-20250725-195342          \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mMetric     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m Mean\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mStd Dev\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m  Min\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m  Max\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mSuccess\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mexact_match\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m0.667\u001b[0m\u001b[32m \u001b[0mâ”‚   0.577 â”‚ 0.000 â”‚ 1.000 â”‚\u001b[33m \u001b[0m\u001b[33m 100.0%\u001b[0m\u001b[33m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mcontains   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m0.667\u001b[0m\u001b[32m \u001b[0mâ”‚   0.577 â”‚ 0.000 â”‚ 1.000 â”‚\u001b[33m \u001b[0m\u001b[33m 100.0%\u001b[0m\u001b[33m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mfuzzy_match\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m0.000\u001b[0m\u001b[32m \u001b[0mâ”‚   0.000 â”‚ 0.000 â”‚ 0.000 â”‚\u001b[33m \u001b[0m\u001b[33m   0.0%\u001b[0m\u001b[33m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print a beautiful summary\n",
    "results.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in different formats\n",
    "results.save_json(\"quickstart_results.json\")\n",
    "print(\"âœ… Saved detailed results to quickstart_results.json\")\n",
    "\n",
    "results.save_csv(\"quickstart_results.csv\")\n",
    "print(\"âœ… Saved summary to quickstart_results.csv (great for Excel!)\")\n",
    "\n",
    "# View timing statistics\n",
    "timing_stats = results.get_timing_stats()\n",
    "print(f\"\\nğŸ“Š Timing Statistics:\")\n",
    "print(f\"  Average time per item: {timing_stats['mean']:.2f}s\")\n",
    "print(f\"  Total evaluation time: {timing_stats['total']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.5: Save Your Results\n",
    "\n",
    "You can save evaluation results for further analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Accuracy: 66.7%\n",
      "Average Similarity: 0.0%\n",
      "\n",
      "Total test cases: 3\n",
      "Success rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Access specific metrics\n",
    "exact_match_stats = results.get_metric_stats(\"exact_match\")\n",
    "print(f\"Exact Match Accuracy: {exact_match_stats['mean']:.1%}\")\n",
    "\n",
    "fuzzy_match_stats = results.get_metric_stats(\"fuzzy_match\")\n",
    "print(f\"Average Similarity: {fuzzy_match_stats['mean']:.1%}\")\n",
    "\n",
    "print(f\"\\nTotal test cases: {results.total_items}\")\n",
    "print(f\"Success rate: {results.success_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Custom Metrics\n",
    "\n",
    "Let's create a custom metric that checks response length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e455b00f06a14215a902e655f79c5483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â•­â”€â”€â”€â”€â”€â”€â”€â”€ Overview â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ <span style=\"font-weight: bold\">Dataset:</span> quickstart-demo â”‚\n",
       "â”‚ <span style=\"font-weight: bold\">Total Items:</span> 3           â”‚\n",
       "â”‚ <span style=\"font-weight: bold\">Success Rate:</span> 100.0%     â”‚\n",
       "â”‚ <span style=\"font-weight: bold\">Duration:</span> 0.6s           â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â•­â”€â”€â”€â”€â”€â”€â”€â”€ Overview â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
       "â”‚ \u001b[1mDataset:\u001b[0m quickstart-demo â”‚\n",
       "â”‚ \u001b[1mTotal Items:\u001b[0m 3           â”‚\n",
       "â”‚ \u001b[1mSuccess Rate:\u001b[0m 100.0%     â”‚\n",
       "â”‚ \u001b[1mDuration:\u001b[0m 0.6s           â”‚\n",
       "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">             Evaluation Results: eval-20250725-195343             </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Metric             </span>â”ƒ<span style=\"font-weight: bold\">  Mean </span>â”ƒ<span style=\"font-weight: bold\"> Std Dev </span>â”ƒ<span style=\"font-weight: bold\">   Min </span>â”ƒ<span style=\"font-weight: bold\">   Max </span>â”ƒ<span style=\"font-weight: bold\"> Success </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> exact_match        </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 0.667 </span>â”‚   0.577 â”‚ 0.000 â”‚ 1.000 â”‚<span style=\"color: #808000; text-decoration-color: #808000\">  100.0% </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> appropriate_length </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 0.667 </span>â”‚   0.577 â”‚ 0.000 â”‚ 1.000 â”‚<span style=\"color: #808000; text-decoration-color: #808000\">  100.0% </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m             Evaluation Results: eval-20250725-195343             \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mMetric            \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m Mean\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mStd Dev\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m  Min\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m  Max\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mSuccess\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mexact_match       \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m0.667\u001b[0m\u001b[32m \u001b[0mâ”‚   0.577 â”‚ 0.000 â”‚ 1.000 â”‚\u001b[33m \u001b[0m\u001b[33m 100.0%\u001b[0m\u001b[33m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mappropriate_length\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m0.667\u001b[0m\u001b[32m \u001b[0mâ”‚   0.577 â”‚ 0.000 â”‚ 1.000 â”‚\u001b[33m \u001b[0m\u001b[33m 100.0%\u001b[0m\u001b[33m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def appropriate_length(output: str, expected: str = None) -> float:\n",
    "    \"\"\"Check if response length is appropriate (not too short, not too long).\"\"\"\n",
    "    length = len(output)\n",
    "    \n",
    "    if length < 5:  # Too short\n",
    "        return 0.0\n",
    "    elif length > 200:  # Too long\n",
    "        return 0.5\n",
    "    else:  # Just right\n",
    "        return 1.0\n",
    "\n",
    "# Run evaluation with custom metric\n",
    "evaluator_custom = Evaluator(\n",
    "    task=simple_qa_bot,\n",
    "    dataset=\"quickstart-demo\",\n",
    "    metrics=[\"exact_match\", appropriate_length]  # Mix built-in and custom\n",
    ")\n",
    "\n",
    "results_custom = evaluator_custom.run()\n",
    "results_custom.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation with auto-save enabled\n",
    "evaluator_autosave = Evaluator(\n",
    "    task=simple_qa_bot,\n",
    "    dataset=\"quickstart-demo\",\n",
    "    metrics=[\"exact_match\", \"fuzzy_match\"]\n",
    ")\n",
    "\n",
    "# Results will be automatically saved with timestamp\n",
    "results_auto = evaluator_autosave.run(\n",
    "    auto_save=True,       # Enable auto-save\n",
    "    save_format=\"json\"    # Choose format: \"json\" or \"csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Results were automatically saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Create more comprehensive datasets** with edge cases\n",
    "2. **Try different metrics** or create custom ones\n",
    "3. **Evaluate real LLM applications** (OpenAI, LangChain, etc.)\n",
    "4. **Set up automated evaluation** in your development workflow\n",
    "5. **Export results** for deeper analysis in your favorite tools\n",
    "\n",
    "### New Features to Try:\n",
    "- Watch the **live progress display** during evaluation\n",
    "- Use **auto-save** to never lose results\n",
    "- Analyze **timing statistics** to optimize performance\n",
    "- Export to **CSV** for Excel analysis and reporting\n",
    "\n",
    "Check out more examples in the examples folder and read the User Guide for detailed instructions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Advanced Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a414b6f025954afa91a91ea72a3adae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: qa-bot-experiment-4\n",
      "Duration: 0.8 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run with custom configuration\n",
    "evaluator_advanced = Evaluator(\n",
    "    task=simple_qa_bot,\n",
    "    dataset=\"quickstart-demo\",\n",
    "    metrics=[\"exact_match\", \"fuzzy_match\"],\n",
    "    config={\n",
    "        \"max_concurrency\": 3,  # Run 3 evaluations in parallel\n",
    "        \"timeout\": 5.0,        # 5 second timeout per test\n",
    "        \"run_name\": \"qa-bot-experiment-4\",\n",
    "        \"run_metadata\": {\n",
    "            \"version\": \"1.0\",\n",
    "            \"notes\": \"Testing basic Q&A functionality\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "results_advanced = evaluator_advanced.run()\n",
    "print(f\"Run name: {results_advanced.run_name}\")\n",
    "print(f\"Duration: {results_advanced.duration:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: View Results in Langfuse\n",
    "\n",
    "Go to your Langfuse dashboard to see:\n",
    "- All evaluation traces\n",
    "- Detailed scoring for each test case\n",
    "- Performance metrics\n",
    "- Comparison between different runs\n",
    "\n",
    "Navigate to: Datasets â†’ quickstart-demo â†’ Experiment runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Create more comprehensive datasets** with edge cases\n",
    "2. **Try different metrics** or create custom ones\n",
    "3. **Evaluate real LLM applications** (OpenAI, LangChain, etc.)\n",
    "4. **Set up automated evaluation** in your development workflow\n",
    "\n",
    "Check out more examples in the examples folder and read the User Guide for detailed instructions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
