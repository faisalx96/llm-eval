version: "3.8"

# LLM-Eval Local One-Line Setup
# Run locally with: docker-compose up

services:
  # Backend API
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: llm-eval-api
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      # Application settings
      API_HOST: 0.0.0.0
      API_PORT: 8000
      LOG_LEVEL: INFO

      # SQLite database (local file)
      DATABASE_URL: sqlite:////app/data/llm_eval.db

      # CORS settings for local frontend
      CORS_ORIGINS: http://localhost:3000

      # Langfuse configuration (users provide their own keys)
      LANGFUSE_SECRET_KEY: ${LANGFUSE_SECRET_KEY}
      LANGFUSE_PUBLIC_KEY: ${LANGFUSE_PUBLIC_KEY}
      LANGFUSE_HOST: ${LANGFUSE_HOST:-https://cloud.langfuse.com}
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    networks:
      - llm-eval-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Frontend (Next.js)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: llm-eval-frontend
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      NEXT_PUBLIC_API_URL: http://localhost:8000
      PORT: 3000
      HOSTNAME: 0.0.0.0
    depends_on:
      - api
    networks:
      - llm-eval-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  # Only need local data volume for SQLite
  data:
    driver: local

networks:
  llm-eval-network:
    driver: bridge
    name: llm-eval-network
